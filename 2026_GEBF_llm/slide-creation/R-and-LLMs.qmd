---
title: "How to get better at R?"
author: "Benjamin Becker & Dries Debeer"
format: 
  revealjs:
    theme: night
    smaller: true
    toc: true
---

# R and RStudio

## What is R?

* a statistical software package

  - statistical modeling and inference
  - read and write data
  - select, filter, and transform data
  - visualize data and models
  
  
* a programming language

  - code for data-analysis, data manipulation, visualization, ...
  - code for text processing, file creation, ....
  
 
  
## R as a Programming Language?

* a programming language 
* clear and logical syntax[^1]
* lot's of R-code available online 
   - CRAN: packages with vignettes and examples, 
   - github, and other repositories, 
   - stack overflow, etc.

$\Rightarrow$ Ideal for training LLMs!

[^1]: R is not always consistent nor logical

 

## What is RStudio?

Rstudio is an Integrated Development Environment (IDE) that focuses on R

It combines: 

  - graphical interface
  - file browser
  - environment overview
  - syntax highlighting
  - keyboard shortcuts
  - ...
  

 
  
## What is RStudio?

RStudio allows integration of:

  - Rmarkdown and quarto
  - git and github
  - large language models
  - ...


 

## What is RStudio?

RStudio can also supports other programming languages (like python).

And there are also other IDE's that are excellent for working with R, and 
also allow an integration of large language models:

* VSCode
* Positron
* ...

 

# Large Language Models

## Which models are available

- OpenAI: GPT-4.1 (also Microsoft/github Copilot)

- Anthorpic: Claude 3.5 Sonnet 

- Alphabet/Google: Google Gemini 2.5 

- Meta: LLaMa 3.1/3.2 $\rightarrow$ open source

- DeepSeek-V3/R1 

- Mistral: Large 2.1 ()

- ...

 


## Interactive chat use vs API use

Interactive chat: 

* a chatbot (like chatGPT, Microsoft Copilot, Claude, ...)
* via a website (with log in)
* with a memory (of the current conversation = *stateful*)
* with a memory of previous conversations
* $\Rightarrow$ with server space for conversations, files, ...
* payment via monthly subscriptions (and free versions)

API use: 

* uses an Application Programming Interface (API) to directly access the LMM
* API differs between providers
* payment per million tokens (some free versions) [pricing](https://pricepertoken.com/leaderboards/coding) 
* without built-in memory (*stateless*)

 


## LLM via chatbots

* [Claude](https://claude.ai/login)
* [ChatGPT](https://chatgpt.com/)
* [Microsoft Copilot](https://copilot.microsoft.com/)

 


## Comparing the results

Disadvantages: 

* R code cannot be run/checked by the chat bots (though python code can)

Advantages:

* history of chat is preserved (within and across chats)

 


## LLM via API

* Through [ellmer](https://ellmer.tidyverse.org/) and RStudio (google gemini account required)
* via the positron integration of github-copilot (github account required)
* Other packages: 

    * [tidyprompt](https://CRAN.R-project.org/package=tidyprompt) Building blocks to construct prompts and handle LLM output.
    * [tidyllm](https://edubruell.github.io/tidyllm/index.html) Alternative for ellmer
    * [rollama](https://jbgruber.github.io/rollama/) Focus on Ollama (which provides local models)
    
 


## `ellmer`

`ellmer` is an R-package (developed by the Posit team). It allows you to use LLMs 
directly for R (and RStudio) via the API option.

Some features:
* supports different LLMs (accounts and API-key are required)
* supports local LLMs
* keeps track of the conversation (makes it *stateful*)
* multiple conversations at the same time.

 


## `ellmer` illustration 


 


## Other R-packages

The `kick()` function of the `side` package creates a *sidekick* that sees the objects in your working environment and can use tools to read and write files, read R documentation, ...

An attempt to build Claude Code or Copilot in R, but still [experimental](https://www.simonpcouch.com/blog/2025-11-11-sidekick/).




 


## LLM via API

Other packages that may be useful: 

* [ragnar](https://ragnar.tidyverse.org/): for implementing Retrieval-Augmented Generation (RAG[^2]) workflows
* [mcptools](https://posit-dev.github.io/mcptools/): for allowing LMM to access your files and data and execute 



[^2]: rather than pre-training a new LLM on a specific corpus. An existing LLM is augmented by adding the relevant corpus (as chunks with an associated vector embedding via the LLM). When queried, a vector embedding for the query is created, which is used to find the most relevant chunks in the corpus. Then, the query and the selected chunks are combined in a new prompt. The result is an answer based on the corpus, often with citations.


 


## Positron Assistant

* Different models can be used, but a subscription (and `API_KEY`) is required
* Github provides auto-complete in addition to chat


 


## Positron Assistant illustration



# Discussion

## How do LLMs work?

## What makes LLMs great learning partners?

LLMs are...

* impressively good at programming tasks
* always available, never tired/annoyed
* can tailor towards all skills levels

 


## How can you use LLMs in your R work?

Let LLMs...

- generate code
- explain concepts/ideas
- point to documentation/learning materials
- review code
- explain existing code


 


## Dangers

- Confabulations/hallucinations (providing incorrect answers confidently)
- dependence on training data (bad with new packages/frameworks)
- LLM rabbit holes ("continuous solution refinement")
- Process vs outcome oriented solutions (programming vs. research)


 


## Rank the trustworthiness of the following sources

- official R-documentation
- package documentation
- wikipedia
- blog article
- co-worker
- student assistant
- chatGPT













# Best practices?


## For Learning the R-language

Ask to explain code with prompts like: 


> You are an expert R coder and experienced data analyst and excellent at explaining code. 
> Explain the following code chunk step by step. Explain what and why.
> 
> <R code>

 


## For Learning the R-language

Ask feedback and improvements on your code.

> You are an expert R coder and experienced data analyst and excellent at explaining code. 
> Improve the following code chunk and explain your improvements step by step. 
> 
> <R code>


 


## For understanding errors

Ask what could cause a specific error to pop up.

> You are an expert R coder and experienced data analyst and excellent at explaining code. 
> explain why the following error-message was returned using the code below.
>
> error message:
>
> <R code>


 


## For writing R-code

For visualizations.
For preprocessing.


 


## For rewriting R-code

For instance you have used both tidyverse code and base code, and would like to limit the 
dependencies.

> Rewrite the following R-code. Only use base-R functionalities. Replace all functions from 
> packages like dplyr and purrr to base-R functions
>
> <R code>

Or when you want to translate python code to R code (or vice versa).

 


## For data-analysis



 


## Be aware of confabulation!

LLMs confabulate. You practically always get a response, even though it may not be correct. 
Without knowledge it is hard to know whether or not confabulation is present.

Therefore, **always make sure you can assess the correctness of the response**.

YES: 

* rewrite my text
* write code for a figure
* interpret the estimates of a fitted model (if you would be able to do it)



 


## Be aware of confabulation!

LLMs confabulate. You practically always get a response, even though it may not be correct. 
Without knowledge it is hard to know whether or not confabulation is present.

Therefore, **always be critical about the response**.

Approach an LLM as a very motivated, really nice, but rather untrustworthy co-worker/assistant/intern with ulterior motives.



 


## And maybe ...

Look at the available documentation first

- Many R-packages have great documentation (including vignettes)

Ask Google first (with AI-mode turned off?).

- There have likely been persons with similar questions/problems (check stack overflow, reddit, ...)
- There are many great tutorials that can be found by web searching



# Bigger Picture 


 


## Current issues

- Ecological consequences of LLM usage
- Ethical issues: Reporting LLM usage in your research (research ethics, ...)


 


## Future issues?

- LLMs are killing Stackoverflow?
- Can LLMs learn new languages/packages/frameworks?
- Technological dependence and monetization issues 
























